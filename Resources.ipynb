{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# AI Hackathon Resources Guide\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the AI Hackathon Resources Guide! This comprehensive collection is designed to help participants navigate through various AI tools, frameworks, and resources needed for successful hackathon projects.\n",
    "\n",
    "### What's Inside:\n",
    "- Essential AI/ML libraries and frameworks\n",
    "- Cloud computing platforms and APIs\n",
    "- Model development and training guides\n",
    "- Best practices and implementation tips\n",
    "\n",
    "### Who Is This For:\n",
    "- Hackathon participants\n",
    "- AI/ML enthusiasts\n",
    "- Data scientists\n",
    "- Software developers\n",
    "- Students and researchers\n",
    "\n",
    "### How to Use This Guide:\n",
    "1. Browse through different sections based on your project needs\n",
    "2. Find relevant tools and resources\n",
    "3. Follow implementation examples and tutorials\n",
    "4. Reference best practices for your development\n",
    "\n",
    "# Useful Resources\n",
    "\n",
    "## LangChain Documentation\n",
    "- [LLM Chain Tutorial](https://python.langchain.com/docs/tutorials/llm_chain/)\n",
    "- [Prompt Templates](https://python.langchain.com/docs/concepts/prompt_templates/)\n",
    "- [How-To Guides](https://python.langchain.com/docs/how_to/)\n",
    "- [Chat Models](https://python.langchain.com/docs/concepts/chat_models/)\n",
    "- [RAG Tutorial](https://python.langchain.com/docs/tutorials/rag/)\n",
    "- [Vector Stores](https://python.langchain.com/docs/concepts/vectorstores/)\n",
    "\n",
    "## Additional Resources\n",
    "- [Getting Started with Embeddings (Hugging Face)](https://huggingface.co/blog/getting-started-with-embeddings)\n",
    "\n",
    "## Video Tutorials\n",
    "- [Rabbitmetrics Tutorial](https://www.youtube.com/watch?v=aywZrzNaKjs)\n",
    "- [Thomas Janssen Tutorial](https://www.youtube.com/watch?v=A3WKdt_MNZQ)\n",
    "\n",
    "Let's dive in and explore the world of AI development resources!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using OpenAi API for LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=\"Insert OpenAiApi Key here\", max_tokens=256)\n",
    "llm.invoke(\"hello\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, Using Groq for LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "UltimateSmallTalker = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",  # Model name for LLM\n",
    "    temperature=0.5,                  # Temperature setting for text generation randomness\n",
    "    api_key=\"insert your groq api key\",  # API key for accessing the LLM service\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Engineering is the practice of designing and optimizing prompts to effectively communicate with AI language models to get desired outputs. It involves crafting specific instructions, context, and constraints to guide the AI in generating accurate and relevant responses.\n",
    "\n",
    "Key aspects of Prompt Engineering:\n",
    "- Understanding how to structure prompts\n",
    "- Using clear and specific language\n",
    "- Providing relevant context\n",
    "- Setting appropriate constraints\n",
    "- Testing and iterating prompt designs\n",
    "\n",
    "Helpful videos on Prompt Engineering:\n",
    "1. \"Prompt Engineering Tutorial\" by Andrew Ng: https://www.youtube.com/watch?v=_ZvnD73m40o\n",
    "2. \"The Art of Prompt Engineering\" - DeepLearning.AI: https://www.youtube.com/watch?v=dOxUroR57xs\n",
    "3. \"Prompt Engineering Guide\" - OpenAI: https://www.youtube.com/watch?v=WO2X3gZFHSM\n",
    "4. \"Mastering ChatGPT Prompts\" - Fireship: https://www.youtube.com/watch?v=jC4v5AS4RIM\n",
    "\n",
    "Exammples of Prompt Template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "rizz_template = \"\"\"You are a Ai Chatbot who helps in Rizz Conversations. You are charismatic and authentic conversationalist who helps write engaging text messages for taha.\n",
    "\n",
    "Current chat:\n",
    "{chat_history}\n",
    "\n",
    "Relevant context:\n",
    "{context}\n",
    "\n",
    "Based on the chat above, craft a message that is:\n",
    "- Keep the messages short and concise as they are for social media\n",
    "- Natural and genuine in tone\n",
    "- Confident yet respectful\n",
    "- Playful and engaging\n",
    "- Uses appropriate emojis when relevant\n",
    "- Matches the other person's energy level\n",
    "- Shows interest while maintaining authenticity\n",
    "- Be persistant\n",
    "- Use flirtlines but only when needed and not too much\n",
    "\n",
    "User Input: {user_input}\n",
    "\n",
    "Write a smooth, engaging response that will naturally keep the conversation flowing:\"\"\"\n",
    "rizz_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\",\"context\", \"user_input\"],\n",
    "    template=rizz_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to Implement Retrival Augmented Generation (RAG)\n",
    "1. Data Preparation\n",
    "   - Collect and organize your documents/data\n",
    "   - Clean and preprocess the text\n",
    "   - Split documents into chunks of appropriate size (to visualize chunking: https://chunkviz.up.railway.app/)\n",
    "   \n",
    "2. Text Embedding\n",
    "   - Convert text chunks into vector embeddings\n",
    "   - Choose an embedding model (e.g., OpenAI, Hugging Face)\n",
    "   - Store embeddings in a vector database (e.g., Chroma, FAISS, Pinecone)\n",
    "\n",
    "3. Setup Vector Store\n",
    "   - Initialize vector database\n",
    "   - Index your embeddings\n",
    "   - Implement similarity search functionality\n",
    "\n",
    "4. Query Processing\n",
    "   - Convert user query to embedding\n",
    "   - Perform similarity search\n",
    "   - Retrieve relevant documents/chunks\n",
    "\n",
    "5. LLM Integration\n",
    "   - Setup LLM (e.g., OpenAI, Anthropic)\n",
    "   - Create prompt template\n",
    "   - Combine retrieved context with user query\n",
    "   - Generate response using LLM\n",
    "\n",
    "Helpful Resources:\n",
    "- LangChain RAG Tutorial: https://www.youtube.com/watch?v=iFvk9cGbIZ4\n",
    "- Building RAG Applications: https://www.youtube.com/watch?v=J_0qvRt4LNk\n",
    "- Advanced RAG Techniques: https://www.youtube.com/watch?v=TRjq7t2Ms5I\n",
    "\n",
    "Remember, RAG is a powerful technique for enhancing LLM performance. Experiment with different embeddings, vector databases, and LLMs to find the best combination for your use case.\n",
    "\n",
    "Below is the code for the RAG implementation using LangChain and OpenAI that we used in the last workshop of the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=10)\n",
    "loader = TextLoader(\"chathistory.txt\") # your text file path (Context)\n",
    "documents = loader.load_and_split(splitter)\n",
    "\n",
    "for doc in documents:\n",
    "    print(doc.page_content)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\") #one of the embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Chroma to store text embeddings in a vector database.\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Create an instance of Chroma to store text embeddings in a vector database.\n",
    "\n",
    "vector_store = Chroma.from_texts(\n",
    "    texts=chunks,  # The list of text chunks to be embedded and stored.\n",
    "    embedding=embeddings_model,  # The model used for generating embeddings from the text chunks.\n",
    "    collection_name=\"example_collection\",  # Name of the collection where data will be stored in the database.\n",
    "    persist_directory=\"./chroma_langchain_db\"  # Directory path where the vector store data will be saved locally. Remove if persistence is not needed.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatively Storing text embeddings in InMemoryVectorStore \n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore.from_documents(documents,embeddings)\n",
    "vector_store.similarity_search(\"hey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing and Generating Dynamic Responses\n",
    "Implementing the conversation flow logic:\n",
    "- Takes a user question about a dating scenario\n",
    "- Updates chat history with the new question\n",
    "- Performs semantic search to find relevant context\n",
    "- Generates a response using our specialized prompt\n",
    "- Updates chat history with the AI's response\n",
    "- Displays the crafted message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"she said she loves taha husssain only?\"\n",
    "chathistory.append(question)\n",
    "docs = [doc.page_content for doc in vector_store.similarity_search(question)]\n",
    "ans = llm.invoke(rizz_prompt.format(chat_history=chathistory,context=docs, user_input=question)).content\n",
    "chathistory.append(ans)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Pitch \n",
    "- Clear and confident delivery\n",
    "- Engaging presentation style\n",
    "- Professional appearance and body language\n",
    "- Time management (staying within allocated time)\n",
    "- Quality of visual aids/slides\n",
    "\n",
    "Helpful YouTube Resources:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
